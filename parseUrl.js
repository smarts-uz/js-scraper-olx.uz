import fs from "fs";
import path from "path";
import puppeteer from "puppeteer";

const sleep = (ms) => new Promise((res) => setTimeout(res, ms));

async function autoScroll(page) {
  await page.evaluate(async () => {
    await new Promise((resolve) => {
      let totalHeight = 0;
      const distance = 400;
      const timer = setInterval(() => {
        const scrollHeight = document.body.scrollHeight;
        window.scrollBy(0, distance);
        totalHeight += distance;
        if (totalHeight >= scrollHeight - window.innerHeight) {
          clearInterval(timer);
          resolve();
        }
      }, 300);
    });
  });
}

async function scrapeAd(url, saveDir, browser) {
  // Extract title from URL without loading the page
  const urlObj = new URL(url);
  let title = urlObj.pathname.split('/').pop() || `olx_ad_${Date.now()}`;
  title = title.replace(/-/g, ' ').replace(/\b\w/g, l => l.toUpperCase());
  
  const urlFileContent = `[InternetShortcut]
URL=${url}
`;
  // –ò–º—è —Ñ–∞–π–ª–∞ = title —Å—Ç—Ä–∞–Ω–∏—Ü—ã
  let safeName = title.replace(/[<>:"/\\|?*]+/g, " ").trim().substring(0, 100);
  if (!safeName) safeName = `olx_ad_${Date.now()}`;
  const filePath = path.join(saveDir, `${safeName}.url`);

  if (!fs.existsSync(saveDir)) {
    fs.mkdirSync(saveDir, { recursive: true });
  }

  fs.writeFileSync(filePath, urlFileContent);
  console.log(`üíæ –°–æ—Ö—Ä–∞–Ω—ë–Ω URL —Ñ–∞–π–ª: ${filePath}`);
}

/**
 * –ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–∞–≥–∏–Ω–∞—Ü–∏–∏
 */
async function getPaginationUrls(page) {
  try {
    // Wait for pagination elements to load
    await page.waitForSelector('ul.pagination-list', { timeout: 10000 }).catch(() => {});
    
    // Scroll to pagination area to ensure all elements are loaded
    await page.evaluate(() => {
      const paginationContainer = document.querySelector('ul.pagination-list');
      if (paginationContainer) {
        paginationContainer.scrollIntoView({ behavior: 'smooth', block: 'end' });
      }
    });
    
    // Add multiple delays and scroll attempts to ensure dynamic content loads
    await sleep(1000);
    
    // Try to click "next" button multiple times to load all pagination links
    let clicked = true;
    let attempts = 0;
    const maxAttempts = 10;
    
    while (clicked && attempts < maxAttempts) {
      clicked = await page.evaluate(() => {
        const nextButton = Array.from(document.querySelectorAll('ul.pagination-list li a'))
          .find(el => el.textContent.trim().toLowerCase() === 'next' || el.textContent.trim() === '¬ª');
        
        if (nextButton && !nextButton.parentElement.classList.contains('active')) {
          nextButton.click();
          return true;
        }
        return false;
      });
      
      if (clicked) {
        await sleep(1500); // Wait for page to load
        attempts++;
      }
    }
    
    // Scroll back to top to ensure we can see all pagination
    await page.evaluate(() => {
      window.scrollTo(0, 0);
    });
    await sleep(1000);
    
    // Get maximum page number from data-testid attributes
    const maxPageNumber = await page.evaluate(() => {
      let maxPage = 0;
      const pageElements = document.querySelectorAll('[data-testid^="pagination-link-"]');
      
      pageElements.forEach(el => {
        const testId = el.getAttribute('data-testid');
        if (testId) {
          const pageNumber = parseInt(testId.replace('pagination-link-', ''));
          if (!isNaN(pageNumber) && pageNumber > maxPage) {
            maxPage = pageNumber;
          }
        }
      });
      
      return maxPage;
    });
    
    // Generate pagination URLs based on page numbers
    const paginationUrls = [];
    if (maxPageNumber > 0) {
      const currentUrl = page.url();
      const urlObj = new URL(currentUrl);
      const baseUrl = `${urlObj.origin}${urlObj.pathname}`;
      
      // Generate URLs for all pages from 2 to maxPageNumber
      for (let i = 2; i <= maxPageNumber; i++) {
        urlObj.searchParams.set('page', i.toString());
        paginationUrls.push(urlObj.toString());
      }
    }
    
    // Also try multiple approaches to get pagination URLs as fallback
    const fallbackUrls = await page.evaluate(() => {
      // Get all pagination links, not just from ul.pagination-list
      const elements = Array.from(document.querySelectorAll('ul.pagination-list a, .pager a'));
      return elements
        .map(el => {
          // Try href attribute first, then href property
          return el.getAttribute('href') || el.href;
        })
        .filter(url => url && !url.includes('javascript:') && !url.includes('#') && url.trim() !== '')
        .map(url => {
          // Make sure URLs are absolute
          if (url.startsWith('/')) {
            const baseUrl = window.location.origin;
            return baseUrl + url;
          }
          return url;
        });
    });
    
    // Also check for data-page attributes or other pagination patterns
    const additionalUrls = await page.evaluate(() => {
      const urls = [];
      const baseUrl = window.location.origin;
      
      // Look for data-page attributes
      const pageElements = document.querySelectorAll('[data-page]');
      pageElements.forEach(el => {
        const page = el.getAttribute('data-page');
        if (page && !isNaN(page)) {
          // Try to construct URL - this is heuristic-based
          const currentUrl = new URL(window.location.href);
          currentUrl.searchParams.set('page', page);
          urls.push(currentUrl.toString());
        }
      });
      
      return urls;
    });
    
    // Combine all found URLs
    const allUrls = [...paginationUrls, ...fallbackUrls, ...additionalUrls];
    
    // Remove duplicates and current page
    const uniqueUrls = [...new Set(allUrls)].filter(url => {
      try {
        const currentUrl = new URL(window.location.href);
        const checkUrl = new URL(url);
        // Filter out current page
        return checkUrl.searchParams.get('page') !== currentUrl.searchParams.get('page') || 
               (checkUrl.searchParams.get('page') === null && currentUrl.searchParams.get('page') === null && url !== window.location.href);
      } catch {
        return true;
      }
    });
    
    return uniqueUrls;
  } catch (error) {
    console.warn("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏:", error.message);
    return [];
  }
}

/**
 * –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤—Å–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–æ–∏—Å–∫–∞, –≤–∫–ª—é—á–∞—è –ø–∞–≥–∏–Ω–∞—Ü–∏—é
 */
export async function scrapeSearch(searchUrl, saveDir, browser = null) {
  let localBrowser = browser;
  let adsCount = 0;

  if (!localBrowser) {
    localBrowser = await puppeteer.launch({
      headless: true,
      slowMo: 100,
      args: ["--no-sandbox", "--disable-setuid-sandbox"],
    });
  }

  // –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–∞–≥–∏–Ω–∞—Ü–∏–∏
  const mainPage = await localBrowser.newPage();
  await mainPage.setViewport({ width: 1280, height: 900 });
  console.log(`üìñ –ó–∞–≥—Ä—É–∂–∞—é –≥–ª–∞–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–∞–≥–∏–Ω–∞—Ü–∏–∏: ${searchUrl}`);
  await mainPage.goto(searchUrl, { waitUntil: "domcontentloaded", timeout: 60000 });
  
  // –ü—Ä–æ–∫—Ä—É—á–∏–≤–∞–µ–º –≤–Ω–∏–∑ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏
  await autoScroll(mainPage);
  await sleep(2000); // –ñ–¥—ë–º –∑–∞–≥—Ä—É–∑–∫—É —ç–ª–µ–º–µ–Ω—Ç–æ–≤
  
  const paginationUrls = await getPaginationUrls(mainPage);
  await mainPage.close();
  
  console.log(`üìë –ù–∞–π–¥–µ–Ω–æ ${paginationUrls.length} —Å—Ç—Ä–∞–Ω–∏—Ü –ø–∞–≥–∏–Ω–∞—Ü–∏–∏`);
  
  // –ï—Å–ª–∏ –ø–∞–≥–∏–Ω–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
  let urlsToProcess = [searchUrl];
  if (paginationUrls.length > 0) {
    // Add original search URL and all pagination URLs
    urlsToProcess = [searchUrl, ...paginationUrls];
    // Remove duplicates
    urlsToProcess = [...new Set(urlsToProcess)];
  }
  
  console.log(`üìÑ –í—Å–µ–≥–æ –±—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ ${urlsToProcess.length} —Å—Ç—Ä–∞–Ω–∏—Ü`);
  
  // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –ø–æ–∏—Å–∫–∞
  for (const [index, url] of urlsToProcess.entries()) {
    console.log(`üìÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Å—Ç—Ä–∞–Ω–∏—Ü—É ${index + 1}/${urlsToProcess.length}: ${url}`);
    
    const page = await localBrowser.newPage();
    await page.setViewport({ width: 1280, height: 900 });
    
    await page.goto(url, { waitUntil: "domcontentloaded", timeout: 60000 });
    await autoScroll(page);
    
    let adLinks = await page.$$eval(
      'a[href*="/obyavlenie/"], a[href*="/offer/"]',
      (els) =>
        els
          .map((el) => el.getAttribute("href"))
          .filter(Boolean)
          .map((href) =>
            href.startsWith("http") ? href : "https://www.olx.uz" + href
          )
    );
    
    // –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    adLinks = [...new Set(adLinks)];
    console.log(`üìå –ù–∞–π–¥–µ–Ω–æ ${adLinks.length} –æ–±—ä—è–≤–ª–µ–Ω–∏–π –Ω–∞ —ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ.`);
    
    await page.close();
    
    // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥–æ–µ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ
    for (const adUrl of adLinks) {
      adsCount++;
      await scrapeAd(adUrl, saveDir, localBrowser);
    }
    
    // –î–µ–ª–∞–µ–º –ø–∞—É–∑—É –º–µ–∂–¥—É —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏
    if (index < urlsToProcess.length - 1) {
      console.log("‚è≥ –ü–∞—É–∑–∞ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ–π...");
      await sleep(3000);
    }
  }

  if (!browser) {
    await localBrowser.close();
  }

  console.log(`üéâ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ ${adsCount} –æ–±—ä—è–≤–ª–µ–Ω–∏–π —Å –ø–æ–∏—Å–∫–∞.`);
}

/**
 * –ü—Ä–∏–Ω–∏–º–∞–µ—Ç –º–∞—Å—Å–∏–≤ –ø–æ–∏—Å–∫–æ–≤ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤—Å–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è
 */
export async function scrapeMultipleSearches(tasks) {
 const browser = await puppeteer.launch({
    headless: true,
    slowMo: 100,
    args: ["--no-sandbox", "--disable-setuid-sandbox"],
  });

  for (const { url, saveDir } of tasks) {
    await scrapeSearch(url, saveDir, browser);
  }

  await browser.close();
  console.log("üéâ –í—Å–µ –ø–æ–∏—Å–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã!");
}

// üöÄ CLI –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
if (process.argv.length >= 4) {
  const url = process.argv[2];
  const saveDir = process.argv[3];

  scrapeSearch(url, saveDir)
    .then(() => {
      console.log("üéâ –ì–æ—Ç–æ–≤–æ!");
    })
    .catch((err) => {
      console.error("‚ùå –û—à–∏–±–∫–∞:", err);
    });
}
